/**************************************************************************************************/
/*                                                                                                */
/*  Informations :                                                                                */
/*      This code is part of the project MLKL                                                     */
/*                                                                                                */
/*  Contacts :                                                                                    */
/*      couet.julien@gmail.com                                                                    */
/*                                                                                                */
/**************************************************************************************************/

require FileIO;
require MLKL; 
 
/**
  The AlembicArchiveReader is a wrapper for the AlembicIArchive. 
  It provides access to the higher level reader objects such as the AlembicXformReader.
  \example

  require MLKL;

  operator entry() {
    
  }

  \endexample
*/

/**************************************************************************************************/
/*                                                  Layer                                         */
const Index MK_LAYER_BASE = 0;
const Index MK_LAYER_INPUT = 1;
const Index MK_LAYER_PARTIAL = 2;
const Index MK_LAYER_FULLY = 3;
const Index MK_LAYER_MAX_POOLING = 4;
const Index MK_LAYER_AVERAGE_POOLING = 5;
const Index MK_LAYER_CONVOLUTIONAL = 6;
const Index MK_LAYER_DROPOUT = 7;


/// Interface of all kind of NN layers
interface MkCNNLayerInterface {
  display();
  Index mode();
  String modeAsStr();
	Index inSize();
	Index outSize();
	Index paramSize();
	Index fanInSize() ;
	Index connectionSize();
  Float64[] output(Index index);
  Float64[] delta(Index index);
  Float64[] weight();
  Float64[] bias();
  Float64[] weightDiff(Index index);
  Float64[] biasDiff(Index index);
  Boolean connect!(io MkCNNLayerInterface tail);
  initWeight!();
  postUpdate!();
  updateWeights!(io Ref<MkCNNOptimizerInterface> o, Index worker_size, Index batch_size) ;
  divideHessian!(Index denominator);
  Ref<MkCNNLayerInterface> prev();
  prev!(Ref<MkCNNLayerInterface> hs);
  Ref<MkCNNLayerInterface> next();
  next!(Ref<MkCNNLayerInterface> hs);
  Ref<MkCNNActivationFunctionInterface> activationFunction();
  Float64[] fprop!(Float64 ins[], Index index);
  Float64[] bprop!(Float64 current_delta[], Index index);
  Float64[] bprop2nd!(Float64 current_delta2[]);
  Boolean save(io TextWriter writer);
  Boolean load!(io TextReader reader);
};

/// Base class of all kind of NN layers
object MkCNNLayerBase : MkCNNLayerInterface {
  protected Index mode;
  protected MkCCNConfig config;
  protected Index in_size;                      // Layer input size
  protected Index out_size;                     // Layer output size
  protected Float64 output[][];                 // last output of current layer, set by fprop
  protected Float64 prev_delta[][];             // last delta of previous layer, set by bprop
  protected Float64 w[];                        // weight vector
  protected Float64 b[];                        // bias vector
  protected Float64 dw[][];                     // difference of weight vector
  protected Float64 db[][];                     // difference of bias vector
  protected Float64 w_hessian[];                // diagonal terms of the wieght hessian matrix 
  protected Float64 b_hessian[];                // diagonal terms of the bias hessian matrix 
  protected Float64 prev_delta2[];              // d^2E/da^2
  protected MkCNNActivationFunctionInterface a; // Activation function
  protected Ref<MkCNNLayerInterface> next;      // Reference to the next layer, foward propagation
  protected Ref<MkCNNLayerInterface> prev;      // Reference to the previous layer, backward propagation
};

/// \internal
/// Initilisation, called by the contructeurs
protected MkCNNLayerBase.setSize!(
  Index in_size, 
  Index out_size, 
  Index weight_size, 
  Index bias_size) 
{
  this.in_size = in_size;
  this.out_size = out_size;
  this.w.resize(weight_size);
  this.b.resize(bias_size);
  this.w_hessian.resize(weight_size);
  this.b_hessian.resize(bias_size);
  this.prev_delta2.resize(in_size);

  for(Index i=0; i<this.output.size(); ++i)
    this.output[i].resize(out_size);

  for(Index i=0; i<this.prev_delta.size(); ++i)
    this.prev_delta[i].resize(in_size);
 
  for(Index i=0; i<this.dw.size(); ++i)
    this.dw[i].resize(weight_size);

  for(Index i=0; i<this.db.size(); ++i)
    this.db[i].resize(bias_size);
}

/// \internal
/// Initilisation, called by the contructeurs
protected MkCNNLayerBase.init!(
  Index activation,
  Index in_size, 
  Index out_size, 
  Index weight_size, 
  Index bias_size) 
{
  this.mode = MK_LAYER_BASE;
  this.output.resize(this.config.taskSize());
  this.prev_delta.resize(this.config.taskSize());
  this.dw.resize(this.config.taskSize());
  this.db.resize(this.config.taskSize());
  this.setSize(in_size, out_size, weight_size, bias_size);

  switch(activation) {
    case MK_ACTIVATION_FUNC_IDENTITY :
      this.a = MkCNNActivationFunctionIdentity();
    break;

     case MK_ACTIVATION_FUNC_SIGMOID :
      this.a = MkCNNActivationFunctionSigmoid();
    break;

     case MK_ACTIVATION_FUNC_RECTIFIEDLINEAR :
      this.a = MkCNNActivationFunctionRectifiedLinear();
    break;

     case MK_ACTIVATION_FUNC_TANH :
      this.a = MkCNNActivationFunctionTanH();
    break;

    default :
      this.a = MkCNNActivationFunctionIdentity();
    break;
  }
}

/// Constructor
public MkCNNLayerBase(
  Index activation,
	Index in_size, 
	Index out_size, 
	Index weight_size, 
	Index bias_size) 
{
  this.init(activation, in_size, out_size, weight_size, bias_size);
}

/// Display the class attributs
public MkCNNLayerBase.display() {
  report("\nMkCNNLayerBase Attributs");
  report("config "          + this.config);
  report("inSize "          + this.in_size);
  report("outSize "         + this.out_size);
  report("weightSize "      + this.w.size());
  report("biasSize "        + this.b.size()); 
  report("paramSize "       + this.paramSize());
  report("fanInSize "       + this.fanInSize()); 
  report("connectionSize "  + this.connectionSize()); 
}

/// Return the current mode
public Index MkCNNLayerBase.mode() {
  return this.mode;
}

/// Display the class attributs
public String MkCNNLayerBase.modeAsStr() {
  
  if(this.mode == MK_LAYER_BASE)
    return "MK_LAYER_BASE";

  else if(this.mode == MK_LAYER_INPUT)
    return "MK_LAYER_INPUT";

  else if(this.mode == MK_LAYER_PARTIAL)
    return "MK_LAYER_PARTIAL";

  else if(this.mode == MK_LAYER_FULLY)
    return "MK_LAYER_FULLY";

  else if(this.mode == MK_LAYER_MAX_POOLING)
    return "MK_LAYER_MAX_POOLING";
 
  else if(this.mode == MK_LAYER_AVERAGE_POOLING)
    return "MK_LAYER_AVERAGE_POOLING";
 
  else if(this.mode == MK_LAYER_CONVOLUTIONAL)
    return "MK_LAYER_CONVOLUTIONAL";
 
  else if(this.mode == MK_LAYER_DROPOUT)
    return "MK_LAYER_DROPOUT";
 
  else
    return "MK_LAYER_UNKNOWN";
}

/// Return the number of layer inputs
public Index MkCNNLayerBase.inSize() { 
  return this.in_size; 
}

/// Return the number of layer ouptuts
public Index MkCNNLayerBase.outSize() { 
  return this.out_size; 
}

/// Return the number of parameters (i.e. the number of weight)
public Index MkCNNLayerBase.paramSize() { 
  return this.w.size() + this.b.size(); 
}

public Index MkCNNLayerBase.fanInSize() {
  return 0;
}

/// Return the total number of layer connections
public Index MkCNNLayerBase.connectionSize() {
  return 0;
}

/// \internal
protected Float64[] MkCNNLayerBase.output(Index index) { 
	return this.output[index]; 
}

/// \internal
protected Float64[] MkCNNLayerBase.delta(Index index) { 
	return this.prev_delta[index]; 
}

/// \internal
protected Float64[] MkCNNLayerBase.weight() { 
	return this.w; 
}

/// \internal
protected Float64[] MkCNNLayerBase.bias() { 
	return this.b; 
}

/// \internal
protected Float64[] MkCNNLayerBase.weightDiff(Index index) {
  return this.dw[index];
}

/// \internal
protected Float64[] MkCNNLayerBase.biasDiff(Index index) {
  return this.db[index];
}

/// \internal
protected Float64[] MkCNNLayerBase.weightHessian() {
  return this.w_hessian;
}

/// \internal
protected Float64[] MkCNNLayerBase.biasHessian() {
  return this.b_hessian;
}

/// \internal
protected Float64[] MkCNNLayerBase.prevDelta2() {
  return this.prev_delta2;
}

/// Check if this and other layers have same weigth
public Boolean MkCNNLayerBase.hasSameWeights(Ref<MkCNNLayerBase> other, Float64 eps) {
  if (this.w.size() != other.w.size() || this.b.size() != other.b.size())
    return false;

  for (Index i = 0; i < this.w.size(); i++)
    if (abs(this.w[i] - other.w[i]) > eps) 
      return false;

  for (Index i = 0; i < this.b.size(); i++)
    if (abs(this.b[i] - other.b[i]) > eps) 
      return false;

  return true;
}

/// Return a pointer to the activation function
public Ref<MkCNNActivationFunctionInterface> MkCNNLayerBase.activationFunction() {
  return this.a;
}

/// Return a pointer to the next layer
public Ref<MkCNNLayerInterface> MkCNNLayerBase.next() {
  return this.next;
}

/// Return a pointer to the previous layer
public Ref<MkCNNLayerInterface> MkCNNLayerBase.prev() {
  return this.prev;
}

/// \internal
/// Set the pointer to the next layer
private MkCNNLayerBase.next!(Ref<MkCNNLayerInterface> layer) {
  this.next = layer;
}

/// \internal
/// Set the pointer to the previous layer
private MkCNNLayerBase.prev!(Ref<MkCNNLayerInterface> layer) {
  this.prev = layer;
}

/// Set the pointer to the next layer
public Boolean MkCNNLayerBase.connect!(io MkCNNLayerInterface tail) {

  if(this.outSize() != 0 && tail.inSize() != this.outSize())
  {
    report("Error : MkCNNLayerBase.connect dimenssion mismatch");
    return false;
  }
  this.next(tail);
  tail.prev(this);
  return true;
}

/// \internal
/// Set to zero the difference vectors dw and db
protected MkCNNLayerBase.clearDiff!(Index worker_size) {
  for (Index i=0; i<worker_size; i++) 
  {
    for(Index j=0; j<this.dw[i].size(); ++j) this.dw[i][j] = 0.0;   
    for(Index j=0; j<this.db[i].size(); ++j) this.db[i][j] = 0.0;  
  }
}

/// \internal
/// Weight layer initialisation
public MkCNNLayerBase.initWeight!() {

  Float64 weight_base = 0.5 / sqrt(this.fanInSize());
  UniformRealDistribution(-weight_base, weight_base, this.w);
  UniformRealDistribution(-weight_base, weight_base, this.b);
  
  for(Index i=0; i<this.w_hessian.size(); ++i) this.w_hessian[i] = 0.0;   
  for(Index i=0; i<this.b_hessian.size(); ++i) this.b_hessian[i] = 0.0;   
  this.clearDiff(this.config.taskSize());
}

/// \internal
/// Called after updating weight
protected MkCNNLayerBase.postUpdate!() {}

/// \internal
/// When using several workers, merge the bias and weight differences
protected MkCNNLayerBase.merge!(Index worker_size, Index batch_size) {

  //for (Index i=1; i<worker_size; i++) {
  //  for(Index j=0; j<this.dw[i].size(); ++j) 
  //    this.dw[0][j] += this.dw[i][j];  
  //
  //  for(Index j=0; j<this.db[i].size(); ++j) 
  //    this.db[0][j] += this.dw[i][j];  
  //}
  for(Index j=0; j<this.dw[0].size(); ++j) 
    this.dw[0][j] /= Float64(batch_size);  
  for(Index j=0; j<this.db[0].size(); ++j) 
    this.db[0][j] /= Float64(batch_size);  
}

/// Update the layer weights, after each batch iteration
public MkCNNLayerBase.updateWeights!(
  io Ref<MkCNNOptimizerInterface> o, 
  Index worker_size, 
  Index batch_size) 
{
  if (this.w.size() == 0) 
    return;

  this.merge(worker_size, batch_size);
  o.update(this.dw[0], this.w_hessian, this.w);
  o.update(this.db[0], this.b_hessian, this.b);

  this.clearDiff(worker_size);
  this.postUpdate();
}

/// Normalization of the hessian
public MkCNNLayerBase.divideHessian!(Index denominator) { 
  for(Index i=0; i<this.w_hessian.size(); ++i) this.w_hessian[i] /= Float64(denominator); 
  for(Index i=0; i<this.b_hessian.size(); ++i) this.b_hessian[i] /= Float64(denominator);   
}

/// Forward propagation
public Float64[] MkCNNLayerBase.fprop!(Float64 ins[], Index index) {
  return ins;
}

/// Backward propagetion 
public Float64[] MkCNNLayerBase.bprop!(Float64 current_delta[], Index index) {
  return current_delta;
}

/// 2nd Backward propagetion 
public Float64[] MkCNNLayerBase.bprop2nd!(Float64 current_delta2[]) {
  return current_delta2;
}

/// Save the layer weights
public Boolean MkCNNLayerBase.save(io TextWriter writer) {
  writer.writeLine("\n" + this.modeAsStr());
  writer.writeLine(this.w);
  writer.writeLine(this.b);
  return true;
}

/// load the layer weights
public Boolean MkCNNLayerBase.load!(io TextReader reader) {

  return true;
}
/*                                                  Layer                                         */
/**************************************************************************************************/

                                          /***********************/

/**************************************************************************************************/
/*                                                Input Layer                                     */
/// Class for input layer 
object MkCNNLayerInput : MkCNNLayerBase {};

/// Constructor
public MkCNNLayerInput() {
  this.init(MK_ACTIVATION_FUNC_IDENTITY, 0, 0, 0, 0);
}

/// Return the number of layer inputs
public Index MkCNNLayerInput.inSize() {
  return (this.next() != null) ? this.next().inSize(): 0;
}

/// Return the number of layer connections
public Index MkCNNLayerInput.connectionSize() { 
  return this.inSize;
}

public Index MkCNNLayerInput.fanInSize() {
  return 1;
}

/// Forward propagation
public Float64[] MkCNNLayerInput.fprop!(Float64 ins[], Index index) {
  this.output[index] = ins;
  return (this.next()!= null) ? this.next().fprop(ins, index) : this.output[index];
}

/// Backward propagetion 
public Float64[] MkCNNLayerInput.bprop!(Float64 current_delta[], Index index) {
  return current_delta;
}

/// 2nd Backward propagetion 
public Float64[] MkCNNLayerInput.bprop2nd!(Float64 current_delta2[]) {
  return current_delta2;
}
/*                                                Input Layer                                     */
/**************************************************************************************************/

                                          /***********************/

/**************************************************************************************************/
/*                                            Max-pooling Layer                                   */
/// Class for max-pooling layer 
object MkCNNLayerMaxPooling : MkCNNLayerBase {
  private Index out2in[][];
  private Index in2out[][];
  private Index out2in_max[];
  private MkCNNIndex3D in_index;
  private MkCNNIndex3D out_index;
};

/// \internal
/// Connect the kernels
private MkCNNLayerMaxPooling.connectKernel!(
  Index pooling_size, 
  Index outx, 
  Index outy, 
  Index c) 
{
  for (Index dy = 0; dy < pooling_size; dy++) 
  {
    for (Index dx = 0; dx < pooling_size; dx++) 
    {
      Index in_index = this.in_index.index(outx * pooling_size + dx, outy * pooling_size + dy, c);
      Index out_index = this.out_index.index(outx, outy, c);
      this.in2out[in_index] = out_index;
      this.out2in[out_index].push(in_index);
    }
  }
}

/// \internal
/// Set the kernel connections
private MkCNNLayerMaxPooling.initConnection!(
  Index in_width, 
  Index in_height, 
  Index in_channels, 
  Index pooling_size) 
{
  this.in2out.resize(this.in_index.size());
  this.out2in.resize(this.out_index.size());
  this.out2in_max.resize(this.out_index.size());
  for (Index c = 0; c < this.in_index.depth; ++c)
  {
    for (Index y = 0; y < this.out_index.height; ++y)
    {
      for (Index x = 0; x < this.out_index.width; ++x)
        this.connectKernel(pooling_size, x, y, c);
    }
  }
}

/// Constructor
public MkCNNLayerMaxPooling(
  Index activation,
  Index in_width, 
  Index in_height, 
  Index in_channels, 
  Index pooling_size) 
{
  this.init(
    activation, 
    in_width * in_height * in_channels, 
    in_width * in_height * in_channels / (pooling_size*pooling_size), 
    0, 0);

  this.in_index = MkCNNIndex3D(in_width, in_height, in_channels);
  this.in_index = MkCNNIndex3D(in_width / pooling_size, in_height / pooling_size, in_channels);
     
  //if ((in_width % pooling_size) || (in_height % pooling_size))
  //  throw nn_error("width/height must be multiples of pooling size");
 
  this.initConnection(in_width, in_height, in_channels, pooling_size);
}

/// Return the total number of layer connections
public Index MkCNNLayerMaxPooling.connectionSize() { 
  return this.out2in[0].size() * this.out2in.size();
}

public Index MkCNNLayerMaxPooling.fanInSize() {
  return this.out2in[0].size();
}

/// \internal
/// Parallalized task for Forward propagation
operator MkCNNLayerMaxPoolingFprop_task<<<i>>>(
  Float64 ins[],
  Index out2in[][],
  io Index out2in_max[],
  io Float64 output[]) 
{
  Index in_index[] = out2in[i];
  Float64 max_value = -10000000000000000;
  
  for (Index j=0; j<in_index.size(); ++j) 
  {
    if (ins[j] > max_value) 
    {
      max_value = ins[j];
      out2in_max[i] = j;
    }
  }
  output[i] = max_value;
}

/// Forward propagation
public Float64[] MkCNNLayerMaxPooling.fprop!(Float64 ins[], Index index) {
  
  Index out2in[][] = this.out2in;
  Index out2in_max[] = this.out2in_max;
  Float64 output[] = this.output[index];

  MkCNNLayerMaxPoolingFprop_task<<<this.out_size>>>(
    ins,
    out2in,
    out2in_max,
    output);
 
  return (this.next()!= null) ? this.next().fprop(output, index) : output;
}

/// \internal
/// Parallalized task for Backward propagation
operator MkCNNLayerMaxPoolingBprop_task<<<i>>>(
  Ref<MkCNNActivationFunctionInterface> prev_h,
  Index out2in_max[],
  Index in2out[][],
  Float64 prev_out[],
  Float64 current_delta[],
  io Float64 prev_delta[]) 
{
  Index outi = in2out[i];
  prev_delta[i] = (out2in_max[outi] == i) ? current_delta[outi] * prev_h.df(prev_out[i]) : 0.0;
}

/// Backward propagetion 
public Float64[] MkCNNLayerMaxPooling.bprop!(Float64 current_delta[], Index index) {
  
  Float64 prev_delta[] = this.prev_delta[index];
  Index in2out[][] = this.in2out;
  Index out2in_max[] = this.out2in_max;
 
  MkCNNLayerMaxPoolingBprop_task<<<this.in_size>>>(
    this.prev().activationFunction(),
    out2in_max,
    in2out,
    this.prev().output(index),
    current_delta,
    prev_delta);

  return this.prev().bprop(this.prev_delta[index], index);
}

/// \internal
/// Parallalized task for 2nd Backward propagation
operator MkCNNLayerMaxPoolingBprop2nd_task<<<i>>>(
  Ref<MkCNNActivationFunctionInterface> prev_h,
  Index out2in_max[],
  Index in2out[][],
  Float64 prev_out[],
  Float64 current_delta2[],
  io Float64 prev_delta2[]) 
{
  Index outi = in2out[i];
  prev_delta2[i] = (out2in_max[outi] == i) ? current_delta2[outi] * prev_h.df(prev_out[i]) * prev_h.df(prev_out[i]) : 0.0;
}

/// 2nd Backward propagetion 
public Float64[] MkCNNLayerMaxPooling.bprop2nd!(Float64 current_delta2[]) {

  Float64 prev_delta2[] = this.prev_delta2;
  Index in2out[][] = this.in2out;
  Index out2in_max[] = this.out2in_max;  
  
  MkCNNLayerMaxPoolingBprop2nd_task<<<this.in_size>>>(
    this.prev().activationFunction(),
    out2in_max,
    in2out,
    this.prev().output(0),
    current_delta2,
    prev_delta2);

  return this.prev().bprop2nd(this.prev_delta2);
}
/*                                            Max-pooling Layer                                   */
/**************************************************************************************************/

                                          /***********************/

/**************************************************************************************************/
/*                                          Layers (Stack of Layer)                               */
/// Class representong a stack of connected layers
object MkCNNLayers {
  private MkCNNLayerInterface layers[];
  private MkCNNLayerInterface first; // Is constrcted as an InputLayer
};

/// \internal
private MkCNNLayers.construct!(io MkCNNLayers rhs) {
  this.add(this.first);
  for (Index i = 1; i < rhs.layers.size(); i++)
    this.add(rhs.layers[i]);
}

/// Constructor
public MkCNNLayers() {
  this.first = MkCNNLayerInput();
  this.add(this.first);
}

/// Display the class attributs
public MkCNNLayers.display() {
  for(Index l=0; l<this.layers.size(); ++l)
    this.layers[l].display();
}

public MkCNNLayers.add!(io MkCNNLayerInterface new_tail) {
  if(this.tail() != null)
    this.tail().connect(new_tail);
  this.layers.push(new_tail);
}

/// Check if there is any layer
public Boolean MkCNNLayers.empty() {
  return (this.layers.size() == 0);
}

/// Return the reference to the first layer
public Ref<MkCNNLayerInterface> MkCNNLayers.head() {
  if(this.empty) return null;
  else return this.layers[0];
}

/// Return the reference to the last layer
public Ref<MkCNNLayerInterface> MkCNNLayers.tail() {
  if(this.empty()) return null;
  else return this.layers[this.layers.size() - 1];
}

/// Reset all the layers weights
public MkCNNLayers.reset!() {
  for(Index l=0; l<this.layers.size(); ++l)
    this.layers[l].initWeight();
}

/// Update the layers weights, after each batch iteration
public MkCNNLayers.updateWeights!(
  io Ref<MkCNNOptimizerInterface> o, 
  Index worker_size, 
  Index batch_size) 
{
  for(Index l=0; l<this.layers.size(); ++l)
    this.layers[l].updateWeights(o, worker_size, batch_size);
}

/// Normalization of the hessian
public MkCNNLayers.divideHessian!(Index denominator) {
  for(Index l=0; l<this.layers.size(); ++l)
    this.layers[l].divideHessian(denominator);
}

/// Save the layers
public Boolean MkCNNLayers.save(io TextWriter writer) {

  // Save the layers weights, append
  for(Index l=0; l<this.layers.size(); ++l)
    if(!this.layers[l].save(writer))
      return false;
  
  return true;
}

/// Load the layers
public Boolean MkCNNLayers.load!(String path) {

  return true;
}
/*                                          Layers (Stack of Layer)                               */
/**************************************************************************************************/
 