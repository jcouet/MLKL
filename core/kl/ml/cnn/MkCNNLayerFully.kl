/**************************************************************************************************/
/*                                                                                                */
/*  Informations :                                                                                */
/*      This code is part of the project MLKL                                                     */
/*                                                                                                */
/*  Contacts :                                                                                    */
/*      couet.julien@gmail.com                                                                    */
/*                                                                                                */
/**************************************************************************************************/

require MLKL; 

/**
  The AlembicArchiveReader is a wrapper for the AlembicIArchive. 
  It provides access to the higher level reader objects such as the AlembicXformReader.
  \example

  require MLKL;

  operator entry() {
    
  }

  \endexample
*/

/**************************************************************************************************/
/*                                          Fully-connected Layer                                 */
/// Class for fully-connected layer 
object MkCNNLayerFully : MkCNNLayerBase {
  protected MkCNNFilterInterface filter;
};

/// Constructor
function MkCNNLayerFully(
  Index activation,
  Index in_size, 
  Index out_size) 
{
  this.init(activation, in_size, out_size, in_size * out_size, out_size);
  this.mode = MK_LAYER_FULLY;
  this.filter = MkCNNFilterNone();
}

/// Display the class attributs
public MkCNNLayerFully.display() {
  this.parent.display();
  report("\nMkCNNLayerFully Attributs");
  report("Filter " + this.filter);
}

/// Return the total number of parameters connections
public Index MkCNNLayerFully.connectionSize() {
  return this.in_size * this.out_size + this.out_size;
}

public Index MkCNNLayerFully.fanInSize() {
  return this.in_size;
}

/// \internal
/// Parallalized task for Forward propagation
operator MkCNNLayerFullyFprop_task<<<i>>>(
  Ref<MkCNNNeuronFunctionInterface> h,
  Index in_size,
  Index out_size,
  Float64 w[],
  Float64 b[],
  Float64 ins[],
  io Float64 output[]) 
{
  Float64 z = 0.0;
  for(Index c=0; c<in_size; c++)
    z += w[c*out_size + i] * ins[c];
  z += b[i];
  output[i] = h.f(z);
}

/// Forward propagation
public Float64[] MkCNNLayerFully.fprop!(Float64 ins[], Index index) {
 
  Ref<MkCNNNeuronFunctionInterface> h = this.activationFunction();
  Index in_size = this.in_size;
  Index out_size = this.out_size;
  Float64 w[] = this.w;
  Float64 b[] = this.b;
  Float64 output[] = this.output[index];
  
  MkCNNLayerFullyFprop_task<<<this.out_size>>>(
    h,
    in_size, 
    out_size, 
    w,
    b,
    ins,
    output);

  Float64 outs[] = this.filter.filterFProp(this.output[index], index);
  return (this.next() != null) ? this.next().fprop(outs, index) : outs;
}

/// \internal
/// Parallalized task for Backward propagation
operator MkCNNLayerFullyBprop_task_1<<<c>>>(
  Ref<MkCNNNeuronFunctionInterface> prev_h,
  Index out_size,
  Float64 prev_out[],
  Float64 w[],
  Float64 current_delta[],
  io Float64 prev_delta[]) 
{
  prev_delta[c] = 0.0;
  for(Index r=0; r<out_size; ++r)
    prev_delta[c] += current_delta[r] * w[c*out_size+r];
  prev_delta[c] *= prev_h.df(prev_out[c]);
}

/// \internal
/// Parallalized task for Backward propagation
operator MkCNNLayerFullyBprop_task_2<<<i>>>(
  Index in_size,
  Index out_size,
  Float64 prev_out[],
  Float64 current_delta[],
  io Float64 dw[],
  io Float64 db[]) 
{
  for (Index c = 0; c < in_size; c++) 
    dw[c*out_size+i] += current_delta[i] * prev_out[c]; 
  db[i] += current_delta[i];
}

/// Backward propagation 
public Float64[] MkCNNLayerFully.bprop!(Float64 current_delta[], Index index) {
  
  Ref<MkCNNNeuronFunctionInterface> prev_h = this.prev().activationFunction();
  Index in_size = this.in_size;
  Index out_size = this.out_size;
  Float64 w[] = this.w;
  Float64 prev_output[] = this.prev().output(index);
  Float64 prev_delta[] = this.prev_delta[index];
  Float64 db[] = this.db[index];
  Float64 dw[] = this.dw[index];

  MkCNNLayerFullyBprop_task_1<<<this.in_size>>>(
    prev_h,
    out_size,
    prev_output,
    w,
    this.filter.filterBProp(current_delta, index),
    prev_delta);

  MkCNNLayerFullyBprop_task_2<<<this.out_size>>>(
    in_size,
    out_size,
    prev_output,
    this.filter.filterBProp(current_delta, index), 
    dw,
    db);

  return this.prev().bprop(this.prev_delta[index], index);
}

/// \internal
/// Parallalized task for 2nd Backward propagation
operator MkCNNLayerFullyBprop2nd_task<<<c>>>(
  Ref<MkCNNNeuronFunctionInterface> prev_h,
  Index out_size,
  Float64 w[],
  Float64 prev_out[],
  Float64 current_delta2[],
  io Float64 w_hessian[],
  io Float64 prev_delta2[]) 
{
  prev_delta2[c] = 0.0;
  for (Index r = 0; r < out_size; r++) 
  {
    prev_delta2[c] += current_delta2[r] * w[c*out_size + r] * w[c*out_size + r];
    w_hessian[c*out_size + r] += current_delta2[r] * prev_out[c] * prev_out[c];
  }
  prev_delta2[c] *= prev_h.df(prev_out[c]) * prev_h.df(prev_out[c]);
}

/// 2nd Backward propagation 
public Float64[] MkCNNLayerFully.bprop2nd!(Float64 current_delta2[]) {
 
  for (Index r=0; r<this.out_size; r++)
    this.b_hessian[r] += current_delta2[r];

  Ref<MkCNNNeuronFunctionInterface> prev_h = this.prev().activationFunction();
  Index out_size = this.out_size;
  Float64 w[] = this.w;
  Float64 prev_output[] = this.prev().output(0);
  Float64 prev_delta2[] = this.prev_delta2;
  Float64 w_hessian[] = this.w_hessian;
  
  MkCNNLayerFullyBprop2nd_task<<<this.in_size>>>(
    prev_h,
    out_size,
    w,
    prev_output, 
    current_delta2,
    w_hessian,
    prev_delta2);

  return this.prev().bprop2nd(this.prev_delta2);
}
/*                                          Fully-connected Layer                                 */
/**************************************************************************************************/

                                          /***********************/

/**************************************************************************************************/
/*                                             Drop-out Layer                                     */
/// Class for average-pooling layer 
object MkCNNLayerDropout : MkCNNLayerFully {};

/// Constructor
function MkCNNLayerDropout(
  Index activation,
  Index in_size, 
  Index out_size, 
  Index weight_size, 
  Index bias_size) 
{
  this.init(activation, in_size, out_size, weight_size, bias_size);
  this.mode = MK_LAYER_DROPOUT;
  this.filter = MkCNNDropout();
}

/// Set the dropout rate
public MkCNNLayerDropout.dropoutRate!(Float64 rate) {
  this.filter.dropoutRate(rate);
}

/// Set dropout-context (training-phase or test-phase)
public MkCNNLayerDropout.context!(Index ctx) {
  this.filter.context(ctx);
}

private MkCNNLayerDropout.postUpdate!() {
  this.filter.endBatch();
}
/*                                             Drop-out Layer                                     */
/**************************************************************************************************/
