//************************************************************************************************//
//                                                                                                //
//  Code part of the project MLKL                                                                 //
//                                                                                                //
//  couet.julien@gmail.com                                                                        //
//                                                                                                //
//************************************************************************************************//

require MLKL; 


/**
  The AlembicArchiveReader is a wrapper for the AlembicIArchive. 
  It provides access to the higher level reader objects such as the AlembicXformReader.
  \example

  require MLKL;

  operator entry() {
    
  }

  \endexample
*/

//************************************************************************************************//
//                                          Fully-connected Layer                                 //
/// Class for fully-connected layer 
object MkCNNLayerFully : MkCNNLayerBase {
  protected MkCNNFilter filter;
};

/// Initilisation, called by the contructeurs
protected MkCNNLayerFully.init!(
  String name,
  Index neuron,
  Index in_size, 
  Index out_size,
  Float64 init_w,
  Float64 init_b) 
{
  this.parent.init(name, neuron, in_size, out_size, in_size * out_size, out_size, init_w, init_b);
  this.mode = MK_LAYER_FULLY;
  this.filter = MkCNNFilterNone();
}

/// Constructor
public MkCNNLayerFully(Index neuron, Index in_size, Index out_size) {
  this.init("", neuron, in_size, out_size, -1.0, -1.0);
}

/// Constructor
public MkCNNLayerFully(
  String name,
  Index neuron,
  Index in_size, 
  Index out_size,
  Float64 init_w,
  Float64 init_b) 
{
  this.init(name, neuron, in_size, out_size, init_w, init_b);
}

/// Display the class attributs
public MkCNNLayerFully.display() {
  this.parent.display();
  report("filter           : " + this.filter);
}

/// Return the total number of parameters connections
public Index MkCNNLayerFully.connectionSize() {
  return this.in_size * this.out_size + this.out_size;
}

public Index MkCNNLayerFully.fanInSize() {
  return this.in_size;
}

/// Parallalized task for Forward propagation
operator MkCNNLayerFullyForward_task<<<i>>>(
  Ref<MkCNNNeuron> neuron,
  Index in_size,
  Index out_size,
  Float64 w[],
  Float64 b[],
  Float64 ins[],
  io Float64 output[]) 
{
  Float64 z = 0.0;
  for(Index c=0; c<in_size; c++)
    z += w[c*out_size + i] * ins[c];
  z += b[i];
  output[i] = neuron.f(z);
}

/// Forward propagation
public Float64[] MkCNNLayerFully.forward!(Float64 ins[], Index index) {
 
  Ref<MkCNNNeuron> neuron = this.neuron();
  Index in_size = this.in_size;
  Index out_size = this.out_size;
  Float64 w[] = this.w;
  Float64 b[] = this.b;
  Float64 output[] = this.output[index];
  
  MkCNNLayerFullyForward_task<<<this.out_size>>>(
    neuron,
    in_size, 
    out_size, 
    w,
    b,
    ins,
    output);

  Float64 outs[] = this.filter.filterForward(this.output[index], index);
  return (this.next() != null) ? this.next().forward(outs, index) : outs;
}

/// Parallalized task for Backward propagation
operator MkCNNLayerFullyBackward_task_1<<<c>>>(
  Ref<MkCNNNeuron> prev_neuron,
  Index out_size,
  Float64 prev_out[],
  Float64 w[],
  Float64 current_delta[],
  io Float64 prev_delta[]) 
{
  prev_delta[c] = 0.0;
  for(Index r=0; r<out_size; ++r)
    prev_delta[c] += current_delta[r] * w[c*out_size+r];
  prev_delta[c] *= prev_neuron.df(prev_out[c]);
}

/// Parallalized task for Backward propagation
operator MkCNNLayerFullyBackward_task_2<<<i>>>(
  Index in_size,
  Index out_size,
  Float64 prev_out[],
  Float64 current_delta[],
  io Float64 dw[],
  io Float64 db[]) 
{
  for (Index c = 0; c < in_size; c++) 
    dw[c*out_size+i] += current_delta[i] * prev_out[c]; 
  db[i] += current_delta[i];
}

/// Backward propagation 
public Float64[] MkCNNLayerFully.backward!(Float64 current_delta[], Index index) {
 
  Ref<MkCNNNeuron> prev_neuron = this.prev().neuron();
  Index in_size = this.in_size;
  Index out_size = this.out_size;
  Float64 w[] = this.w;
  Float64 prev_output[] = this.prev().output(index);
  Float64 prev_delta[] = this.prev_delta[index];
  Float64 db[] = this.db[index];
  Float64 dw[] = this.dw[index];

  MkCNNLayerFullyBackward_task_1<<<this.in_size>>>(
    prev_neuron,
    out_size,
    prev_output,
    w,
    this.filter.filterBackward(current_delta, index),
    prev_delta);

  MkCNNLayerFullyBackward_task_2<<<this.out_size>>>(
    in_size,
    out_size,
    prev_output,
    this.filter.filterBackward(current_delta, index), 
    dw,
    db);

  return this.prev().backward(this.prev_delta[index], index);
}

/// Parallalized task for 2nd Backward propagation
operator MkCNNLayerFullyBackward2_task<<<c>>>(
  Ref<MkCNNNeuron> prev_neuron,
  Index out_size,
  Float64 w[],
  Float64 prev_out[],
  Float64 current_delta2[],
  io Float64 w_hessian[],
  io Float64 prev_delta2[]) 
{
  prev_delta2[c] = 0.0;
  for (Index r = 0; r < out_size; r++) 
  {
    prev_delta2[c] += current_delta2[r] * w[c*out_size + r] * w[c*out_size + r];
    w_hessian[c*out_size + r] += current_delta2[r] * prev_out[c] * prev_out[c];
  }
  prev_delta2[c] *= prev_neuron.df(prev_out[c]) * prev_neuron.df(prev_out[c]);
}

/// 2nd Backward propagation 
public Float64[] MkCNNLayerFully.backward2!(Float64 current_delta2[]) {
 
  for (Index r=0; r<this.out_size; r++)
    this.b_hessian[r] += current_delta2[r];

  Ref<MkCNNNeuron> prev_neuron = this.prev().neuron();
  Index out_size = this.out_size;
  Float64 w[] = this.w;
  Float64 prev_output[] = this.prev().output(0);
  Float64 prev_delta2[] = this.prev_delta2;
  Float64 w_hessian[] = this.w_hessian;
  
  MkCNNLayerFullyBackward2_task<<<this.in_size>>>(
    prev_neuron,
    out_size,
    w,
    prev_output, 
    current_delta2,
    w_hessian,
    prev_delta2);

  return this.prev().backward2(this.prev_delta2);
}
//                                          Fully-connected Layer                                //
//************************************************************************************************//

                                          //*********************//

//************************************************************************************************//
//                                             Drop-out Layer                                     //
/// Class for average-pooling layer 
object MkCNNLayerDropout : MkCNNLayerFully {};

/// Constructor
private MkCNNLayerDropout.init!(
  String name,
  Index neuron,
  Index in_size, 
  Index out_size, 
  Float64 init_w,
  Float64 init_b) 
{
  this.parent.init(name, neuron, in_size, out_size, init_w, init_b);
  this.mode = MK_LAYER_DROPOUT;
  this.filter = MkCNNDropout();
}

/// Constructor
public MkCNNLayerDropout(Index neuron, Index in_size, Index out_size) {
  this.init("", neuron, in_size, out_size, -1.0, -1.0);
}

/// Constructor
public MkCNNLayerDropout(
  String name,
  Index neuron,
  Index in_size, 
  Index out_size, 
  Float64 init_w,
  Float64 init_b) 
{
  this.init(name, neuron, in_size, out_size, init_w, init_b);
}

/// Set the dropout rate
public MkCNNLayerDropout.dropoutRate!(Float64 rate) {
  this.filter.dropoutRate(rate);
}

/// Set dropout-context (training-phase or test-phase)
public MkCNNLayerDropout.context!(Index ctx) {
  this.filter.context(ctx);
}

private MkCNNLayerDropout.postUpdate!() {
  this.filter.endBatch();
}
//                                             Drop-out Layer                                     //
//************************************************************************************************//
